full_fit
summary(full_fit)
summary(stepwise.model)
summary(model)
summary(stepwise.model)
ggpairs(stepwise.model)
library(GGally)
install.packages("GGally")
install.packages("GGally")
library(GGally)
ggpairs(stepwise.model)
plot(stepwise.model)
plot(stepwise.model)
plot(AttrAdj,OverTime)
plot(a$AttrAdj,a$OverTime)
plot(log(a$AttrAdj),a$OverTime)
plot(a$MaritalStatus,a$OverTime)
plot(a$JobRole,a$OverTime)
summary(stepwise.model)
stepwise.model <- lm(formula = AttrAdj ~ OverTime + MaritalStatus + JobRole + Gender +
BusinessTravel + YearsWithCurrManager +
YearsSinceLastPromotion + YearsInCurrentRole + YearsAtCompany +
WorkLifeBalance + TrainingTimesLastYear + TotalWorkingYears +
RelationshipSatisfaction + NumCompaniesWorked + JobSatisfaction +
JobInvolvement + EnvironmentSatisfaction + DistanceFromHome +
Age, data = a)
summary(stepwise.model)
stepwise.model <- lm(formula = scale(AttrAdj) ~ scale(OverTime) + MaritalStatus + JobRole + Gender +
EducationField + BusinessTravel + YearsWithCurrManager +
YearsSinceLastPromotion + YearsInCurrentRole + YearsAtCompany +
WorkLifeBalance + TrainingTimesLastYear + TotalWorkingYears +
RelationshipSatisfaction + NumCompaniesWorked + JobSatisfaction +
JobInvolvement + EnvironmentSatisfaction + DistanceFromHome +
Age, data = a)
ls_step_best_subset(full_fit)
install.packages("Olsrr")
library(Olsrr)
install.packages("olsrr")
install.packages("olsrr")
install.packages("olsrr")
install.packages("olsrr")
library(olsrr)
ls_step_best_subset(full_fit)
install.packages("olsrr")
install.packages("olsrr")
library(olsrr)
ls_step_best_subset(full_fit)
ols_step_best_subset(full_fit)
library(olsrr)
a <-read.csv("F:/SMU/DS6306/Case Study 2/TalentManagement.csv")
full_fit <- lm(AttrAdj ~ OverTime +
MaritalStatus +
JobRole +
Gender +
EducationField +
Department +
BusinessTravel +
YearsWithCurrManager +
YearsSinceLastPromotion +
YearsInCurrentRole +
YearsAtCompany +
WorkLifeBalance +
TrainingTimesLastYear +
TotalWorkingYears +
StockOptionLevel +
RelationshipSatisfaction +
PerformanceRating +
PercentSalaryHike +
NumCompaniesWorked +
MonthlyRate +
MonthlyIncome +
JobSatisfaction +
JobLevel +
JobInvolvement +
HourlyRate +
EnvironmentSatisfaction +
Education +
DistanceFromHome +
DailyRate +
Age, data = a)
a$AttrAdj[a$Attrition == "Yes"] <- 1
a$AttrAdj[a$Attrition == "No"] <- 0
full_fit <- lm(AttrAdj ~ OverTime +
MaritalStatus +
JobRole +
Gender +
EducationField +
Department +
BusinessTravel +
YearsWithCurrManager +
YearsSinceLastPromotion +
YearsInCurrentRole +
YearsAtCompany +
WorkLifeBalance +
TrainingTimesLastYear +
TotalWorkingYears +
StockOptionLevel +
RelationshipSatisfaction +
PerformanceRating +
PercentSalaryHike +
NumCompaniesWorked +
MonthlyRate +
MonthlyIncome +
JobSatisfaction +
JobLevel +
JobInvolvement +
HourlyRate +
EnvironmentSatisfaction +
Education +
DistanceFromHome +
DailyRate +
Age, data = a)
ols_step_best_subset(full_fit)
summary(stepwise.model)
step(full_fit, direction="both")
stepwise.model <- lm(formula = AttrAdj ~ OverTime + MaritalStatus + JobRole + Gender +
EducationField + BusinessTravel + YearsWithCurrManager +
YearsSinceLastPromotion + YearsInCurrentRole + YearsAtCompany +
WorkLifeBalance + TrainingTimesLastYear + TotalWorkingYears +
RelationshipSatisfaction + NumCompaniesWorked + JobSatisfaction +
JobInvolvement + EnvironmentSatisfaction + DistanceFromHome +
Age, data = a)
summary(stepwise.model)
ols_step_best_subset(stepwise.model)
# Read in dataset cleanup dataset, identifies is.na and any columns we do not want to use.
a <-read.csv("F:/SMU/DS6306/Case Study 2/TalentManagement.csv")
a$AttrAdj[a$Attrition == "Yes"] <- 1
a$AttrAdj[a$Attrition == "No"] <- 0
full_fit <- lm(AttrAdj ~ OverTime +
MaritalStatus +
JobRole +
Gender +
EducationField +
Department +
BusinessTravel +
YearsWithCurrManager +
YearsSinceLastPromotion +
YearsInCurrentRole +
YearsAtCompany +
WorkLifeBalance +
TrainingTimesLastYear +
TotalWorkingYears +
StockOptionLevel +
RelationshipSatisfaction +
PerformanceRating +
PercentSalaryHike +
NumCompaniesWorked +
MonthlyRate +
MonthlyIncome +
JobSatisfaction +
JobLevel +
JobInvolvement +
HourlyRate +
EnvironmentSatisfaction +
Education +
DistanceFromHome +
DailyRate +
Age, data = a)
step(full_fit, direction="both")
ab <- lm(formula = AttrAdj ~ OverTime + MaritalStatus + JobRole + Gender +
EducationField + BusinessTravel + YearsWithCurrManager +
YearsSinceLastPromotion + YearsInCurrentRole + YearsAtCompany +
WorkLifeBalance + TrainingTimesLastYear + TotalWorkingYears +
RelationshipSatisfaction + NumCompaniesWorked + JobSatisfaction +
JobInvolvement + EnvironmentSatisfaction + DistanceFromHome +
Age, data = a)
summary(ab)
plot(ab)
library(MASS)
library(mvtnorm)
library(MASS)
set.seed(1234)
dataYes<-mvrnorm(30,c(10,10),matrix(c(1,.8,.8,1),2,2,byrow=T))
dataYes
dataNo<- mvrnorm(30,c(10,7),matrix(c(1,.8,.8,1),2,2,byrow=T))
full<-rbind(dataYes,dataNo)
full
full<-data.frame(full)
full
full$Response<-rep(c("Yes","No"),each=30)
full$Response<-factor(full$Response)
names(full)[1:2]<-c("X1","X2")
plot(full[, 1:2], col = full$Response, main="Shift in X2")
#Another scenario
dataYes<-mvrnorm(30,c(10,10),matrix(c(1,.6,.6,1),2,2,byrow=T))
dataNo<- mvrnorm(30,c(8,8),matrix(c(1,.6,.6,1),2,2,byrow=T))
full<-rbind(dataYes,dataNo)
full<-data.frame(full)
full$Response<-rep(c("Yes","No"),each=30)
full$Response<-factor(full$Response)
names(full)[1:2]<-c("X1","X2")
plot(full[, 1:2], col = full$Response, main="Shift in X2")
points(mylda$means, pch = "+", cex = 2, col = c("black", "red"))
contour(x = nd.x, y = nd.y, z = matrix(prd, nrow = np, ncol = np),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
# construct the LDA model
mylda <- lda(Response ~ X1 + X2, data = full)
# draw discrimination line
np <- 300
nd.x <- seq(from = min(full$X1), to = max(full$X1), length.out = np)
nd.y <- seq(from = min(full$X2), to = max(full$X2), length.out = np)
nd <- expand.grid(X1 = nd.x, X2 = nd.y)
prd <- as.numeric(predict(mylda, newdata = nd)$class)
plot(full[, 1:2], col = full$Response, main="Shift in X2")
points(mylda$means, pch = "+", cex = 2, col = c("black", "red"))
contour(x = nd.x, y = nd.y, z = matrix(prd, nrow = np, ncol = np),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
?lda
mylda <- lda(Response ~ X1 + X2, prior = 0.8, data = full)
mylda <- lda(Response ~ X1 + X2,  data = full, prior = 0.8)
mylda <- lda(Response ~ X1 + X2,  data = full, prior = c(1,1,1)/3)
full
mylda <- lda(Response ~ X1 + X2,  data = full, prior = prior)
mylda <- lda(Response ~ X1 + X2,  data = full, prior = c(1,1)/3)
mylda <- lda(Response ~ X1 + X2,  data = full, prior = c(1,1,1)/3)
mylda <- lda(Response ~ X1 + X2,  data = full, prior = c(1,1,1,1)/3)
mylda <- lda(Response ~ X1 + X2,  data = full, prior = c(1,1,1)/2)
full[61,1]<-11
full[61,2]<-0
full[61,3]<-"Yes"
mylda <- lda(Response ~ X1 + X2, data = full)
# draw discrimination line
np <- 300
nd.x <- seq(from = min(full$X1), to = max(full$X1), length.out = np)
nd.y <- seq(from = min(full$X2), to = max(full$X2), length.out = np)
nd <- expand.grid(X1 = nd.x, X2 = nd.y)
prd <- as.numeric(predict(mylda, newdata = nd)$class)
plot(full[, 1:2], col = full$Response, main="Shift in X2")
points(mylda$means, pch = "+", cex = 2, col = c("black", "red"))
contour(x = nd.x, y = nd.y, z = matrix(prd, nrow = np, ncol = np),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
library(mvtnorm)
set.seed(1234)
muYes<-c(10,10)
muNo<-c(8,8)
Sigma<-matrix(c(1,.8,.8,1),2,2,byrow=T)
nY<-30
nN<-30
dataYes<-rmvnorm(nY,muYes,Sigma)
dataNo<- rmvnorm(nN,muNo,Sigma)
train<-rbind(dataYes,dataNo)
train<-data.frame(train)
for (i in 3:20){
train<-cbind(train,rnorm(nY+nN))
}
names(train)<-paste("X",1:20,sep="")
train$Response<-rep(c("Yes","No"),each=30)
train$Response<-factor(train$Response)
#Creating a test set
muYes<-c(10,10)
muNo<-c(8,8)
Sigma<-matrix(c(1,.8,.8,1),2,2,byrow=T)
nY<-500
nN<-500
dataYes<-rmvnorm(nY,muYes,Sigma)
dataNo<- rmvnorm(nN,muNo,Sigma)
test<-rbind(dataYes,dataNo)
test<-data.frame(test)
for (i in 3:20){
test<-cbind(test,rnorm(nY+nN))
}
names(test)<-paste("X",1:20,sep="")
test$Response<-rep(c("Yes","No"),each=500)
test$Response<-factor(test$Response)
mylda<-lda(Response~X1+X2,data=train)
pred<-predict(mylda,newdata=test)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Response
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/1000
ME
1-ME
mylda<-lda(Response~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10,data=train)
pred<-predict(mylda,newdata=test)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Response
x<-table(pred,Truth) # Creating a confusion matrix
x
mylda<-lda(Response~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17+X18+X19+X20,data=train)
pred<-predict(mylda,newdata=test)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Response
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/1000
ME
1-ME
# 10 predictors
mylda<-lda(Response~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10,data=train)
pred<-predict(mylda,newdata=test)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Response
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/1000
ME
1-ME
# All 20 predictors
mylda<-lda(Response~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17+X18+X19+X20,data=train)
pred<-predict(mylda,newdata=test)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Response
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/1000
ME
1-ME
library(Lahman)
install.packages("Lahman")
library(Lahman)
data(Batting)
index<-which(Batting$yearID==2016)
Bat16<-Batting[index,]
summary(Bat16)
reduced<-Bat16[,6:10]
pairs(reduced)
apply(reduced,2,summary)
var.raw<-apply(reduced,2,var)
var.raw
sum(var.raw)
sum(diag(cov(reduced)))
pc.result<-prcomp(reduced,scale.=FALSE)
pc.scores<-pc.result$x
pc.result<-prcomp(reduced,scale.=FALSE)
pc.scores<-pc.result$x
pairs(pc.scores)
cor(pc.scores)
var.pca<-apply(pc.scores,2,var)
var.pca
#Total Variance of PC's
sum(var.pca)
#Total Variance of Original Variables.
sum(var.raw)
#List of eigenvectors
pc.result$rotation
par(mfrow=c(1,2))
eigenvals<-(pc.result$sdev)^2
plot(1:5,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:5,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
par(mfrow=c(1,1))
Bat16
reduced<-Bat16[,6:23]
reduced<-Bat16[,6:22]
par(mfrow=c(1,2))
eigenvals<-(pc.result$sdev)^2
plot(1:5,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:5,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
pc.result<-prcomp(reduced,scale.=FALSE)
par(mfrow=c(1,2))
eigenvals<-(pc.result$sdev)^2
plot(1:5,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:5,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
par(mfrow=c(1,2))
eigenvals<-(pc.result$sdev)^2
plot(1:5,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:22,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:21,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:10,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:2,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
pc.result
plot(1:8,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:15,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:14,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:10,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:5,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
eigenvals
plot(1:17,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
plot(1:17,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:17,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
par(mfrow=c(1,2))
eigenvals<-(pc.result$sdev)^2
plot(1:17,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:17,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
pc.result$rotation
bc<-read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=F,sep=",")
names(bc)<- c('id_number', 'diagnosis', 'radius_mean',
'texture_mean', 'perimeter_mean', 'area_mean',
'smoothness_mean', 'compactness_mean',
'concavity_mean','concave_points_mean',
'symmetry_mean', 'fractal_dimension_mean',
'radius_se', 'texture_se', 'perimeter_se',
'area_se', 'smoothness_se', 'compactness_se',
'concavity_se', 'concave_points_se',
'symmetry_se', 'fractal_dimension_se',
'radius_worst', 'texture_worst',
'perimeter_worst', 'area_worst',
'smoothness_worst', 'compactness_worst',
'concavity_worst', 'concave_points_worst',
'symmetry_worst', 'fractal_dimension_worst')
#Getting a look at the distribution
table(bc$diagnosis)
##
##   B   M
## 357 212
#Scatter plots color coded by response for just the first few variables
pairs(bc[,3:6],col=bc$diagnosis)
pc.bc<-prcomp(bc[,-c(1,2)],scale.=TRUE)
pc.bc.scores<-pc.bc$x
#Adding the response column to the PC's data frame
pc.bc.scores<-data.frame(pc.bc.scores)
pc.bc.scores$Diagnosis<-bc$diagnosis
#Use ggplot2 to plot the first few pc's
library(ggplot2)
ggplot(data = pc.bc.scores, aes(x = PC1, y = PC2)) +
geom_point(aes(col=Diagnosis), size=1)+
ggtitle("PCA of Breast Cancer Tumor Biopsies")
ggplot(data = pc.bc.scores, aes(x = PC2, y = PC3)) +
geom_point(aes(col=Diagnosis), size=1)+
ggtitle("PCA of Breast Cancer Tumor Biopsies")
mylda <- lda(diagnosis ~ ., data = bc)
library(MASS)
library(mvtnorm)
mylda <- lda(diagnosis ~ ., data = bc)
mylda
summary(mylda)
np <- 300
nd.x <- seq(from = min(full$X1), to = max(full$X1), length.out = np)
nd.y <- seq(from = min(full$X2), to = max(full$X2), length.out = np)
nd <- expand.grid(X1 = nd.x, X2 = nd.y)
prd <- as.numeric(predict(mylda, newdata = nd)$class)
plot(full[, 1:2], col = full$Response, main="Shift in X2")
points(mylda$means, pch = "+", cex = 2, col = c("black", "red"))
contour(x = nd.x, y = nd.y, z = matrix(prd, nrow = np, ncol = np),
levels = c(1, 2), add = TRUE, drawlabels = FALSE)
fake<-bc
fake$diagnosis<-sample(fake$diagnosis,569,replace=F)
fake
#Scatter plots color coded by response for just the first few variables
pairs(fake[,3:6],col=bc$diagnosis)
pc.bc<-prcomp(fake[,-c(1,2)],scale.=TRUE)
pc.bc.scores<-pc.bc$x
pc.bc.scores<-data.frame(pc.bc.scores)
pc.bc.scores$Diagnosis<-fake$diagnosis
#Use ggplot2 to plot the first few pc's
library(ggplot2)
ggplot(data = pc.bc.scores, aes(x = PC1, y = PC2)) +
geom_point(aes(col=Diagnosis), size=1)+
ggtitle("PCA of Breast Cancer Tumor Biopsies")
ggplot(data = pc.bc.scores, aes(x = PC2, y = PC3)) +
geom_point(aes(col=Diagnosis), size=1)+
ggtitle("PCA of Breast Cancer Tumor Biopsies")
library(ggplot2)
ggplot(data = pc.bc.scores, aes(x = PC1, y = PC2)) +
geom_point(aes(col=Diagnosis), size=1)+
ggtitle("PCA of Breast Cancer Tumor Biopsies")
ggplot(data = pc.bc.scores, aes(x = PC2, y = PC3)) +
geom_point(aes(col=Diagnosis), size=1)+
ggtitle("PCA of Breast Cancer Tumor Biopsies")
mylda <- lda(diagnosis ~ ., data = fake)
mylda
mylda <- lda(diagnosis ~ ., data = fake)
pred<-predict(mylda,newdata=fake)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-test$Response
x<-table(pred,Truth) # Creating a confusion matrix
x
prop.test(335,411,p=.7,correct=TRUE)  #correct is the continuity correction option
vit.c<-data.frame(Supp=rep(c("Placebo","Vitamin C"),times=c(411,407)),
Cold=rep(c("Yes","No","Yes","No"),times=c(335,76,302,105)))
head(vit.c)
mymat<-table(vit.c)   # or table(vit.c$Supp,vit.c$Cold)
mymat
mymat<-matrix(c(76,335,105,302),2,2,byrow=T,dimnames=list(c("Placebo","Vitamin C"),c("No","Yes")))
mymat
#Conducting a fishers exact test
fisher.test(mymat)
#Conducting a chi square test
chisq.test(mymat,correct=TRUE)
prop.table(mymat,margin=1)
prop.test(mymat,correct=TRUE)
prop.test(mymat[,c(2,1)],correct=TRUE)
prop.test(mymat[c(2,1),c(2,1)],correct=TRUE)
library(epitools)
#Another way to format a count matrix
mymat<-matrix(c(76,335,105,302),2,2,byrow=T)
dimnames(mymat)<-list("Treatment"=c("Plac","Vit C"),"Response"=c("No","Yes"))
mymat
#Odds Ratio Intervals
oddsratio.wald(mymat)
install.packages("epitools")
library(epitools)
mymat<-matrix(c(76,335,105,302),2,2,byrow=T)
dimnames(mymat)<-list("Treatment"=c("Plac","Vit C"),"Response"=c("No","Yes"))
mymat
#Odds Ratio Intervals
oddsratio.wald(mymat)
#Relative Risk Intervals
riskratio.wald(mymat)
#Relative Risk Intervals
riskratio.wald(mymat)
oddsratio.wald(mymat)
oddsratio.wald(mymat, rev="both")
#Odds Ratio Intervals
oddsratio.wald(mymat, rev="row")
#Odds Ratio Intervals
oddsratio.wald(mymat, rev="columns")
#Odds Ratio Intervals
oddsratio.wald(mymat, rev="rows")
#Relative Risk Intervals
riskratio.wald(mymat)
#Relative Risk Intervals
riskratio.wald(mymat, rev"rows")
#Relative Risk Intervals
riskratio.wald(mymat, rev="rows")
setwd("F:/SMU/DS6372/Project 2/STATS_6372_Project2/Data")
medData <- read.csv(file="DJ_Project2_Data.csv", header=TRUE)
medData
